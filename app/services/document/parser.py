# -*- coding: utf-8 -*-
"""
Docling Complete + Chunking í†µí•© íŒŒì„œ

docling_complete.pyì˜ Docling ì „ì²˜ë¦¬ + chunk_docling.pyì˜ Dual Content ì²­í‚¹ì„
í•˜ë‚˜ë¡œ í†µí•©í•œ ì›ìŠ¤í†± PDF ì²˜ë¦¬ ëª¨ë“ˆì…ë‹ˆë‹¤.

Features:
- Docling Completeì˜ ëª¨ë“  ê¸°ëŠ¥ (OCR ìë™ ê°ì§€, VLM/LLM description, ì´ë¯¸ì§€/í…Œì´ë¸” PNG ì €ì¥)
- Dual Content ì²­í‚¹ (ê²€ìƒ‰ìš© content + LLMìš© content_for_llm)
- ë©”ëª¨ë¦¬ ê¸°ë°˜ ì²˜ë¦¬ (íŒŒì¼ I/O ìµœì†Œí™”)
- ë‹¨ì¼ í•¨ìˆ˜ í˜¸ì¶œë¡œ PDF â†’ Chunksê¹Œì§€ ì™„ë£Œ

Usage:
    >>> from complete_chunker import DoclingChunker
    >>>
    >>> # ê¸°ë³¸ ëª¨ë“œ (PNG ì €ì¥ë§Œ)
    >>> chunker = DoclingChunker()
    >>> chunks, metadata = chunker.process_pdf_to_chunks(pdf_bytes, "test.pdf", output_dir)
    >>>
    >>> # ê³ ê¸‰ ëª¨ë“œ (VLM/LLM description ì¶”ê°€)
    >>> chunker = DoclingChunker(advanced_mode=True)
    >>> chunks, metadata = chunker.process_pdf_to_chunks(pdf_bytes, "test.pdf", output_dir)
"""
import json
import logging
import re
import io
import base64
import unicodedata
import os
from pathlib import Path
from typing import Optional, Dict, Any, List, Tuple, Set
from dataclasses import dataclass
from uuid import uuid5, NAMESPACE_DNS

import fitz  # PyMuPDF
import requests
from PIL import Image
import nltk
from nltk.tokenize import sent_tokenize

# Config import
from app.services.rag.config import RAGConfig

# Note: CUDA_VISIBLE_DEVICES ì„¤ì • ì œê±°
# VLM/LLMì€ vLLM APIë¥¼ í†µí•´ í˜¸ì¶œë˜ë¯€ë¡œ ë¡œì»¬ GPU ì„¤ì • ë¶ˆí•„ìš”
# ì „ì—­ CUDA_VISIBLE_DEVICES ì„¤ì •ì€ ë‹¤ë¥¸ ëª¨ë“ˆ(retriever ë“±)ì˜ GPU ì ‘ê·¼ì„ ë°©í•´í•¨

from docling.datamodel.base_models import InputFormat
from docling.datamodel.pipeline_options import (
    PdfPipelineOptions,
    RapidOcrOptions,
    EasyOcrOptions,
    TesseractCliOcrOptions,
)
from docling.document_converter import DocumentConverter, PdfFormatOption
from docling_core.types.doc import DoclingDocument, PictureItem, TableItem

# NLTK ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ìµœì´ˆ 1íšŒë§Œ í•„ìš”)
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    logging.info("Downloading NLTK 'punkt' tokenizer...")
    nltk.download('punkt', quiet=True)
try:
    nltk.data.find('tokenizers/punkt_tab')
except LookupError:
    nltk.download('punkt_tab', quiet=True)


@dataclass
class OCRDetectionResult:
    """OCR ê°ì§€ ê²°ê³¼"""
    needs_ocr: bool
    reason: str
    avg_chars_per_page: float
    has_images: bool
    has_corrupted_text: bool
    recommended_lang: list[str]
    total_pages: int
    text_layer_ratio: float  # í…ìŠ¤íŠ¸ ë ˆì´ì–´ê°€ ìˆëŠ” í˜ì´ì§€ ë¹„ìœ¨


# ===== í—¬í¼ í•¨ìˆ˜ =====
def _collapse_ws_keep_newlines(text: str) -> str:
    """ê³µë°±ì„ ì••ì¶•í•˜ë˜ ì¤„ë°”ê¿ˆì€ ìœ ì§€"""
    if not text:
        return ""
    lines = text.split('\n')
    collapsed = []
    for line in lines:
        collapsed.append(' '.join(line.split()))
    return '\n'.join(collapsed)


def _docling_table_to_markdown(table_data: Dict[str, Any]) -> str:
    """Docling í…Œì´ë¸” ë°ì´í„°ë¥¼ Markdownìœ¼ë¡œ ë³€í™˜"""
    # table_cellsëŠ” data ì•ˆì— ìˆìŒ
    data = table_data.get("data", {})
    cells = data.get("table_cells")
    if not cells:
        return ""

    data_list = []
    max_row, max_col = 0, 0

    for cell in cells:
        r_start = cell.get("start_row_offset_idx", 0)
        c_start = cell.get("start_col_offset_idx", 0)
        text = (_collapse_ws_keep_newlines(cell.get("text", "")) or "").replace('\n', ' ').strip()

        # íŒŒì´í”„ ë¬¸ì ì´ìŠ¤ì¼€ì´í”„
        text = text.replace("|", "\\|")

        if text:
            data_list.append({"row": r_start, "col": c_start, "text": text})
            max_row = max(max_row, r_start)
            max_col = max(max_col, c_start)

    if not data_list:
        return ""

    table_array = [["" for _ in range(max_col + 1)] for _ in range(max_row + 1)]
    for item in data_list:
        r, c = item['row'], item['col']
        if 0 <= r <= max_row and 0 <= c <= max_col:
            table_array[r][c] = item['text']

    # Markdown í…Œì´ë¸” ìƒì„±
    if not table_array:
        return ""

    lines = []
    for idx, row in enumerate(table_array):
        lines.append("| " + " | ".join(row) + " |")
        if idx == 0:
            lines.append("|" + "|".join([" --- " for _ in row]) + "|")

    return "\n".join(lines)


class DoclingChunker:

    """
    Docling Complete + Dual Content ì²­í‚¹ í†µí•© í´ë˜ìŠ¤

    docling_complete.pyì™€ chunk_docling.pyì˜ ë¡œì§ì„ í•˜ë‚˜ë¡œ í†µí•©í•˜ì—¬
    PDF â†’ JSON â†’ Chunksê¹Œì§€ ì›ìŠ¤í†±ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.

    Example:
        >>> # ê¸°ë³¸ ëª¨ë“œ
        >>> chunker = DoclingChunker()
        >>> chunks, metadata = chunker.process_pdf_to_chunks(pdf_bytes, "test.pdf", output_dir)
        >>>
        >>> # ê³ ê¸‰ ëª¨ë“œ (VLM/LLM description ìƒì„±)
        >>> chunker = DoclingChunker(advanced_mode=True)
        >>> chunks, metadata = chunker.process_pdf_to_chunks(pdf_bytes, "test.pdf", output_dir)
    """

    def __init__(
        self,
        # Docling Complete ì˜µì…˜ (config ê¸°ë³¸ê°’ ì‚¬ìš©)
        image_scale: float = None,
        enable_table_structure: bool = True,
        auto_detect_ocr: bool = True,
        force_ocr: bool = False,
        force_no_ocr: bool = False,
        ocr_engine: str = "tesseract",
        ocr_threshold: float = None,

        # ê³ ê¸‰ ëª¨ë“œ ì˜µì…˜
        advanced_mode: bool = False,
        enable_image_description: bool = True,
        enable_table_description: bool = True,
        filter_junk_images: bool = True,

        # LLM/VLM ì„¤ì • (config ê¸°ë³¸ê°’ ì‚¬ìš©)
        llm_model: str = None,
        vision_model: str = None,
        ollama_url: str = None,

        # í”„ë¡¬í”„íŠ¸
        image_description_prompt: str = """Analyze this image and determine if it's meaningful content or junk.

JUNK images include: QR codes, barcodes, logos, decorative elements, page numbers, headers/footers, book covers, irrelevant graphics.

If the image is JUNK, respond with exactly: "JUNK"

If the image contains meaningful technical/scientific content (diagrams, charts, photos, illustrations), provide a concise description in English focusing on key components and technical details. Limit to 3-5 sentences.""",
        table_description_prompt: str = "Analyze this table (provided in markdown format) and provide a concise summary in English. Explain what data it contains and any key insights. Limit to 3-5 sentences.",

        # ì²­í‚¹ ì˜µì…˜ (config ê¸°ë³¸ê°’ ì‚¬ìš©)
        max_tokens: int = None,
        min_chunk_tokens: int = None,
        include_descriptions: bool = True,
        embed_with_assets: bool = False,

        # Progress callback
        progress_callback: Optional[callable] = None,
    ):
        """
        Args:
            # Docling Complete ì˜µì…˜
            image_scale: ì´ë¯¸ì§€ í•´ìƒë„ ìŠ¤ì¼€ì¼ (ê¸°ë³¸: 2.0)
            enable_table_structure: í…Œì´ë¸” êµ¬ì¡° ë¶„ì„ í™œì„±í™” (ê¸°ë³¸: True)
            auto_detect_ocr: OCR í•„ìš” ì—¬ë¶€ ìë™ ê°ì§€ (ê¸°ë³¸: True)
            force_ocr: OCR ê°•ì œ í™œì„±í™” (ê¸°ë³¸: False)
            force_no_ocr: OCR ê°•ì œ ë¹„í™œì„±í™” (ê¸°ë³¸: False)
            ocr_engine: OCR ì—”ì§„ ì„ íƒ - tesseract(í•œêµ­ì–´ ìš°ìˆ˜), easyocr(ë‹¤êµ­ì–´), rapidocr(ë¹ ë¦„)
            ocr_threshold: OCR í•„ìš” íŒë‹¨ ì„ê³„ê°’ - í…ìŠ¤íŠ¸ ë ˆì´ì–´ ë¹„ìœ¨ (ê¸°ë³¸: 0.4 = 40%)

            # ê³ ê¸‰ ëª¨ë“œ
            advanced_mode: ê³ ê¸‰ ëª¨ë“œ í™œì„±í™” (ê¸°ë³¸ ëª¨ë“œ: ì´ë¯¸ì§€/í…Œì´ë¸” PNG ì €ì¥ë§Œ, ê³ ê¸‰ ëª¨ë“œ: VLM/LLM description ì¶”ê°€ ìƒì„±)
            enable_image_description: ì´ë¯¸ì§€ VLM description ìƒì„± (advanced_mode=Trueì¼ ë•Œë§Œ ë™ì‘)
            enable_table_description: í…Œì´ë¸” LLM description ìƒì„± (advanced_mode=Trueì¼ ë•Œë§Œ ë™ì‘)
            filter_junk_images: JUNKìœ¼ë¡œ ë¶„ë¥˜ëœ ì´ë¯¸ì§€ í•„í„°ë§ (ê¸°ë³¸: True)

            # LLM/VLM ì„¤ì •
            llm_model: LLM ëª¨ë¸ëª…
            vision_model: VLM vision ëª¨ë¸ëª…
            ollama_url: vLLM ì„œë²„ URL

            # í”„ë¡¬í”„íŠ¸
            image_description_prompt: ì´ë¯¸ì§€ description í”„ë¡¬í”„íŠ¸
            table_description_prompt: í…Œì´ë¸” description í”„ë¡¬í”„íŠ¸

            # ì²­í‚¹ ì˜µì…˜
            max_tokens: í…ìŠ¤íŠ¸ ì²­í¬ë‹¹ ìµœëŒ€ í† í° ìˆ˜ (ê¸°ë³¸: 400, asset ì¶”ê°€ ì „)
            min_chunk_tokens: ì²­í¬ ìµœì†Œ í† í° ìˆ˜ (ê¸°ë³¸: 100, ì´ë³´ë‹¤ ì‘ìœ¼ë©´ ì´ì „ ì²­í¬ì— ë³‘í•©)
            include_descriptions: ì´ë¯¸ì§€/í…Œì´ë¸” descriptionì„ í¬í•¨í• ì§€ ì—¬ë¶€ (ê¸°ë³¸: True)
            embed_with_assets: content í•„ë“œì—ë„ ì—ì…‹ ì„¤ëª…ì„ appendixë¡œ ì¶”ê°€ (ê¸°ë³¸: False)
        """
        # Docling ì˜µì…˜ (config ê¸°ë³¸ê°’ ì‚¬ìš©)
        self.image_scale = image_scale if image_scale is not None else RAGConfig.DOCLING_IMAGE_SCALE
        self.enable_table_structure = enable_table_structure
        self.auto_detect_ocr = auto_detect_ocr
        self.force_ocr = force_ocr
        self.force_no_ocr = force_no_ocr
        self.ocr_engine = ocr_engine.lower()
        self.ocr_threshold = ocr_threshold if ocr_threshold is not None else RAGConfig.DOCLING_OCR_THRESHOLD

        # ê³ ê¸‰ ëª¨ë“œ ì˜µì…˜
        self.advanced_mode = advanced_mode
        self.enable_image_description = enable_image_description and advanced_mode
        self.enable_table_description = enable_table_description and advanced_mode
        self.filter_junk_images = True if advanced_mode else filter_junk_images

        # LLM/VLM ì„¤ì • (config ê¸°ë³¸ê°’ ì‚¬ìš©)
        self.llm_model = llm_model if llm_model is not None else RAGConfig.DOCLING_LLM_MODEL
        self.vision_model = vision_model if vision_model is not None else RAGConfig.DOCLING_VISION_MODEL
        # VLM URL (ì´ë¯¸ì§€ descriptionìš©, Port 8002)
        self.vlm_url = ollama_url if ollama_url is not None else RAGConfig.VLM_URL
        # LLM URL (í…Œì´ë¸” descriptionìš©, Port 8003)
        self.llm_url = RAGConfig.FOLLOW_UP_LLM_URL

        # í”„ë¡¬í”„íŠ¸
        self.image_description_prompt = image_description_prompt
        self.table_description_prompt = table_description_prompt

        # ì²­í‚¹ ì˜µì…˜ (config ê¸°ë³¸ê°’ ì‚¬ìš©)
        self.max_tokens = max_tokens if max_tokens is not None else RAGConfig.CHUNK_MAX_TOKENS
        self.min_chunk_tokens = max(0, min_chunk_tokens if min_chunk_tokens is not None else RAGConfig.CHUNK_MIN_TOKENS)
        self.include_descriptions = include_descriptions
        self.embed_with_assets = embed_with_assets

        # Progress callback
        self.progress_callback = progress_callback

        self.logger = logging.getLogger(__name__)

        # ê³ ê¸‰ ëª¨ë“œ ì„¤ì • ë¡œê¹…
        self.logger.info(
            f"DoclingChunker ì„¤ì • ì™„ë£Œ: advanced_mode={self.advanced_mode}, "
            f"enable_image_description={self.enable_image_description}, "
            f"enable_table_description={self.enable_table_description}, "
            f"vlm_url={self.vlm_url}, llm_url={self.llm_url}"
        )

        # OCR ê²°ê³¼ ì €ì¥ìš©
        self.last_ocr_result = None

        # ìƒí˜¸ ë°°íƒ€ì  ì˜µì…˜ ê²€ì¦
        if self.force_ocr and self.force_no_ocr:
            raise ValueError("force_ocrì™€ force_no_ocrëŠ” ë™ì‹œì— Trueì¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ì œì™¸í•  label ëª©ë¡
        self.exclude_labels = {
            'page_header',
            'page_footer',
        }

        # ì •ê·œì‹ íŒ¨í„´
        self.ref_re = re.compile(r"^#/(texts|groups|tables|pictures)/(\d+)$", re.I)

    # ===== Docling Complete ë©”ì„œë“œ =====

    def _generate_vlm_description(self, image: Image.Image) -> Optional[str]:
        """vLLM VLMì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ description ìƒì„± (Port 8002: Qwen VLM)"""
        try:
            self.logger.info(f"VLM description ìƒì„± ì‹œì‘: url={self.vlm_url}, model={self.vision_model}")
            buffer = io.BytesIO()
            image.save(buffer, format="PNG")
            img_base64 = base64.b64encode(buffer.getvalue()).decode("utf-8")

            response = requests.post(
                f"{self.vlm_url}/v1/chat/completions",
                json={
                    "model": self.vision_model,
                    "messages": [
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": self.image_description_prompt},
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/png;base64,{img_base64}"
                                    }
                                }
                            ]
                        }
                    ],
                    "max_tokens": 512,
                    "temperature": 0.1,
                    "top_p": 0.9,
                },
                timeout=60
            )

            if response.status_code == 200:
                desc = response.json()["choices"][0]["message"]["content"].strip()
                self.logger.debug(f"VLM description ìƒì„± ì„±ê³µ ({len(desc)} chars)")
                return desc
            else:
                self.logger.warning(f"VLM API error: {response.status_code}")
                return None
        except Exception as e:
            self.logger.warning(f"VLM description ì‹¤íŒ¨: {e}")
            return None

    def _generate_llm_table_description(self, markdown_table: str) -> Optional[str]:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ í…Œì´ë¸” ë§ˆí¬ë‹¤ìš´ ìš”ì•½ ìƒì„±"""
        if not markdown_table or len(markdown_table.strip()) == 0:
            return None

        try:
            prompt = f"{self.table_description_prompt}\n\n{markdown_table}"
            return self._call_vllm_text(prompt)

        except Exception as e:
            self.logger.warning(f"LLM table description ì‹¤íŒ¨: {e}")
            return None

    def _call_vllm_text(self, prompt: str) -> Optional[str]:
        """vLLM í…ìŠ¤íŠ¸ ëª¨ë¸ í˜¸ì¶œ (Port 8003: GPT-OSS-20B)"""
        try:
            self.logger.info(f"LLM text ìƒì„± ì‹œì‘: url={self.llm_url}, model={self.llm_model}")
            response = requests.post(
                f"{self.llm_url}/v1/chat/completions",
                json={
                    "model": self.llm_model,
                    "messages": [
                        {"role": "user", "content": prompt}
                    ],
                    "max_tokens": 1024,
                    "temperature": 0.1,
                    "top_p": 0.9,
                },
                timeout=60
            )

            if response.status_code == 200:
                return response.json()["choices"][0]["message"]["content"].strip()
            else:
                self.logger.error(f"vLLM API error: {response.status_code}")
                return None

        except Exception as e:  
            self.logger.error(f"vLLM API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return None

    def detect_ocr_requirement(self, pdf_path: Path) -> OCRDetectionResult:
        """PDF êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ OCR í•„ìš” ì—¬ë¶€ë¥¼ íŒë‹¨"""
        doc = fitz.open(str(pdf_path))
        total_pages = len(doc)
        total_chars = 0
        has_images = False
        has_corrupted = False
        sample_text = ""

        pages_with_text_layer = 0

        for page in doc:
            text = page.get_text("text")
            total_chars += len(text.strip())
            sample_text += text[:1000]

            # PDF êµ¬ì¡° ë¶„ì„
            text_dict = page.get_text("dict")
            blocks = text_dict.get("blocks", [])

            has_text_block = False
            has_image_block = False

            for block in blocks:
                block_type = block.get("type", -1)
                if block_type == 0:  # í…ìŠ¤íŠ¸ ë¸”ë¡
                    lines = block.get("lines", [])
                    for line in lines:
                        spans = line.get("spans", [])
                        for span in spans:
                            span_text = span.get("text", "").strip()
                            if span_text:
                                has_text_block = True
                                break
                elif block_type == 1:  # ì´ë¯¸ì§€ ë¸”ë¡
                    has_image_block = True

            if has_text_block:
                pages_with_text_layer += 1
            if has_image_block:
                has_images = True

            # ê¹¨ì§„ ë¬¸ì ê°ì§€
            if "GLYPH<" in text:
                has_corrupted = True
            if re.search(r'[\u0300-\u036f]{3,}', text):
                has_corrupted = True
            if re.search(r'[\ufffd]{2,}', text):
                has_corrupted = True

        doc.close()

        avg_chars = total_chars / total_pages if total_pages > 0 else 0
        text_layer_ratio = pages_with_text_layer / total_pages if total_pages > 0 else 0

        # ì–¸ì–´ ê°ì§€
        recommended_lang = ["en"]
        if re.search(r'[\uac00-\ud7af]', sample_text):  # í•œêµ­ì–´
            recommended_lang = ["ko"]
        elif re.search(r'[\u4e00-\u9fff]', sample_text):  # ì¤‘êµ­ì–´
            recommended_lang = ["ch"]
        elif re.search(r'[\u3040-\u30ff]', sample_text):  # ì¼ë³¸ì–´
            recommended_lang = ["ja"]

        # OCR í•„ìš” ì—¬ë¶€ íŒë‹¨
        needs_ocr = False
        reason = "í…ìŠ¤íŠ¸ ì¶”ì¶œ ì •ìƒ"

        if has_corrupted:
            needs_ocr = True
            reason = "ê¹¨ì§„ ë¬¸ì/GLYPH íƒœê·¸ ê°ì§€ - OCR í•„ìš”"
        elif text_layer_ratio < self.ocr_threshold:
            needs_ocr = True
            reason = f"í…ìŠ¤íŠ¸ ë ˆì´ì–´ ë¶€ì¡± ({pages_with_text_layer}/{total_pages} í˜ì´ì§€, {text_layer_ratio:.0%} < {self.ocr_threshold:.0%})"
        else:
            needs_ocr = False
            reason = f"í…ìŠ¤íŠ¸ ë ˆì´ì–´ ì¶©ë¶„ ({pages_with_text_layer}/{total_pages} í˜ì´ì§€, {text_layer_ratio:.0%} >= {self.ocr_threshold:.0%})"

        return OCRDetectionResult(
            needs_ocr=needs_ocr,
            reason=reason,
            avg_chars_per_page=avg_chars,
            has_images=has_images,
            has_corrupted_text=has_corrupted,
            recommended_lang=recommended_lang,
            total_pages=total_pages,
            text_layer_ratio=text_layer_ratio,
        )

    def _create_converter(self, ocr_result: Optional[OCRDetectionResult] = None) -> DocumentConverter:
        """DocumentConverter ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        pdf_opts = PdfPipelineOptions()
        pdf_opts.images_scale = self.image_scale
        pdf_opts.generate_page_images = True
        pdf_opts.generate_picture_images = True
        pdf_opts.do_table_structure = self.enable_table_structure

        # OCR í™œì„±í™” ì—¬ë¶€ ê²°ì •
        enable_ocr = False
        if self.force_no_ocr:
            enable_ocr = False
            self.logger.info("OCR ê°•ì œ ë¹„í™œì„±í™”")
        elif self.force_ocr:
            enable_ocr = True
            self.logger.info("OCR ê°•ì œ í™œì„±í™”")
        elif self.auto_detect_ocr and ocr_result:
            enable_ocr = ocr_result.needs_ocr
            self.logger.info(f"OCR ìë™ ê°ì§€: {ocr_result.reason}")

        pdf_opts.do_ocr = enable_ocr

        # OCR í™œì„±í™” ì‹œ ì—”ì§„ ì„ íƒ
        if enable_ocr and ocr_result:
            lang = ocr_result.recommended_lang[0] if ocr_result.recommended_lang else "en"

            if self.ocr_engine == "tesseract":
                tesseract_lang_map = {
                    "ko": ["kor", "eng"],
                    "ja": ["jpn", "eng"],
                    "ch": ["chi_sim", "chi_tra", "eng"],
                    "en": ["eng"],
                }
                tesseract_lang = tesseract_lang_map.get(lang, ["eng"])
                ocr_options = TesseractCliOcrOptions(
                    force_full_page_ocr=True,
                    lang=tesseract_lang,
                )
                self.logger.info(f"Tesseract OCR í™œì„±í™” (ì–¸ì–´: {tesseract_lang})")
            elif self.ocr_engine == "easyocr":
                easyocr_lang_map = {
                    "ko": ["ko", "en"],
                    "ja": ["ja", "en"],
                    "ch": ["ch_sim", "en"],
                    "en": ["en"],
                }
                ocr_options = EasyOcrOptions(
                    force_full_page_ocr=True,
                    lang=easyocr_lang_map.get(lang, ["en"]),
                )
                self.logger.info(f"EasyOCR í™œì„±í™” (ì–¸ì–´: {easyocr_lang_map.get(lang, ['en'])})")
            else:
                ocr_options = RapidOcrOptions(
                    force_full_page_ocr=True,
                    lang=ocr_result.recommended_lang,
                )
                self.logger.info(f"RapidOCR í™œì„±í™” (ì–¸ì–´: {ocr_result.recommended_lang})")

            pdf_opts.ocr_options = ocr_options

        return DocumentConverter(
            format_options={InputFormat.PDF: PdfFormatOption(pipeline_options=pdf_opts)}
        )

    def convert_to_dict(self, pdf_path: Path, assets_dir: Path) -> dict:
        """
        PDF íŒŒì¼ì„ DoclingDocumentë¡œ ë³€í™˜ í›„ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜

        Args:
            pdf_path: ë³€í™˜í•  PDF íŒŒì¼ ê²½ë¡œ
            assets_dir: ì—ì…‹ ì €ì¥ ë””ë ‰í† ë¦¬

        Returns:
            ë³€í™˜ëœ ë”•ì…”ë„ˆë¦¬
        """
        if not pdf_path.exists():
            raise FileNotFoundError(f"PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")

        if not pdf_path.suffix.lower() == ".pdf":
            raise ValueError(f"PDF íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤: {pdf_path}")

        self.logger.info(f"PDF ë³€í™˜ ì‹œì‘: {pdf_path.name}")

        # OCR ê°ì§€
        ocr_result = None
        if self.auto_detect_ocr and not self.force_ocr and not self.force_no_ocr:
            self.logger.info("OCR í•„ìš” ì—¬ë¶€ ë¶„ì„ ì¤‘...")
            ocr_result = self.detect_ocr_requirement(pdf_path)
            self.logger.info(f"  - ì´ í˜ì´ì§€: {ocr_result.total_pages}")
            self.logger.info(f"  - í…ìŠ¤íŠ¸ ë ˆì´ì–´ ë¹„ìœ¨: {ocr_result.text_layer_ratio:.1%}")
            self.logger.info(f"  - í‰ê·  ë¬¸ì/í˜ì´ì§€: {ocr_result.avg_chars_per_page:.0f}")
            self.logger.info(f"  - ê¹¨ì§„ ë¬¸ì ê°ì§€: {ocr_result.has_corrupted_text}")
            self.logger.info(f"  - ê¶Œì¥ ì–¸ì–´: {ocr_result.recommended_lang}")
            self.logger.info(f"  - ê²°ì •: {ocr_result.reason}")

        # OCR ê²°ê³¼ ì €ì¥ (metadataì— í¬í•¨ì‹œí‚¤ê¸° ìœ„í•´)
        self.last_ocr_result = ocr_result

        # ë³€í™˜ ì‹¤í–‰
        converter = self._create_converter(ocr_result)
        result = converter.convert(pdf_path)
        doc = result.document

        self.logger.info(f"PDF ë³€í™˜ ì™„ë£Œ: {pdf_path.name}")

        # ì²« ë²ˆì§¸ íŒ¨ìŠ¤: PictureItemì—ì„œ classification ì¶”ì¶œ
        classification_map = {}
        img_idx_temp = 0
        for item, _level in doc.iterate_items():
            if isinstance(item, PictureItem):
                for annot in item.annotations:
                    if hasattr(annot, 'predicted_classes') and annot.predicted_classes:
                        best_class = max(annot.predicted_classes, key=lambda x: x.confidence)
                        classification_map[img_idx_temp] = best_class.class_name
                        self.logger.debug(f"ì´ë¯¸ì§€ {img_idx_temp} classification: {best_class.class_name} (confidence: {best_class.confidence:.3f})")
                        break
                img_idx_temp += 1

        # DoclingDocumentë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        doc_dict = doc.export_to_dict()

        # classificationì„ doc_dictì— ì¶”ê°€
        pictures = doc_dict.get("pictures", [])
        for idx, classification in classification_map.items():
            if idx < len(pictures):
                pictures[idx]["classification"] = classification

        if classification_map:
            self.logger.info(f"ğŸ“ Classification ì¶”ì¶œ ì™„ë£Œ: {len(classification_map)}ê°œ ì´ë¯¸ì§€")

        # ì—ì…‹ ë””ë ‰í† ë¦¬ ì„¤ì •
        images_dir = assets_dir / "images"
        tables_dir = assets_dir / "tables"
        images_dir.mkdir(parents=True, exist_ok=True)
        tables_dir.mkdir(parents=True, exist_ok=True)

        self.logger.info(f"ì—ì…‹ ì €ì¥ ë””ë ‰í† ë¦¬: {assets_dir}")

        # ì´ë¯¸ì§€ ë° í…Œì´ë¸” ì²˜ë¦¬
        img_idx = 0
        tbl_idx = 0

        # JUNK ì´ë¯¸ì§€ ì¸ë±ìŠ¤ ìˆ˜ì§‘
        junk_image_indices: set[int] = set()
        if self.filter_junk_images:
            junk_image_indices = {
                i for i, pic in enumerate(doc_dict.get("pictures", []))
                if isinstance(pic, dict) and pic.get("classification") == "JUNK"
            }
            if junk_image_indices:
                self.logger.info(f"ğŸ—‘ï¸  JUNK ì´ë¯¸ì§€ {len(junk_image_indices)}ê°œ í•„í„°ë§")

        # ê³ ê¸‰ ëª¨ë“œ ì¹´ìš´í„°
        total_tables = len(doc_dict.get("tables", []))
        total_images = len(doc_dict.get("pictures", []))

        if self.advanced_mode:
            self.logger.info(f"ğŸ“Š ê³ ê¸‰ ëª¨ë“œ: í…Œì´ë¸” {total_tables}ê°œ, ì´ë¯¸ì§€ {total_images - len(junk_image_indices)}ê°œ ì²˜ë¦¬ ì‹œì‘")
            table_desc_count = 0
            image_desc_count = 0
            junk_skipped = 0

        for item, _level in doc.iterate_items():
            # í…Œì´ë¸” ì²˜ë¦¬
            if isinstance(item, TableItem):
                try:
                    # í…Œì´ë¸” ì´ë¯¸ì§€ ì €ì¥
                    img = item.get_image(doc)
                    table_path = tables_dir / f"table-{tbl_idx}.png"
                    img.save(table_path, "PNG")
                    self.logger.debug(f"í…Œì´ë¸” ì €ì¥: {table_path}")

                    # ê³ ê¸‰ ëª¨ë“œ: LLM description ìƒì„±
                    if self.enable_table_description and "tables" in doc_dict:
                        if tbl_idx < len(doc_dict["tables"]):
                            table_node = doc_dict["tables"][tbl_idx]

                            # ë§ˆí¬ë‹¤ìš´ ë³€í™˜
                            markdown_table = _docling_table_to_markdown(table_node)
                            if markdown_table:
                                self.logger.info(f"ğŸ”„ í…Œì´ë¸” description ìƒì„± ì¤‘ [{tbl_idx + 1}/{total_tables}]...")

                                # Progress callback í˜¸ì¶œ
                                if self.progress_callback:
                                    self.progress_callback({
                                        'status': f'Generating table description [{tbl_idx + 1}/{total_tables}]',
                                        'progress': 40 + int((tbl_idx / total_tables) * 20),
                                        'current_table': tbl_idx + 1,
                                        'total_tables': total_tables,
                                    })

                                # LLM ìš”ì•½ ìƒì„±
                                desc = self._generate_llm_table_description(markdown_table)
                                if desc:
                                    if "annotations" not in table_node:
                                        table_node["annotations"] = []
                                    table_node["annotations"].append({
                                        "kind": "description",
                                        "label": "llm_table_summary",
                                        "text": desc
                                    })
                                    table_desc_count += 1
                                    self.logger.info(f"âœ… í…Œì´ë¸” [{tbl_idx + 1}/{total_tables}] description ì™„ë£Œ (ì´ {table_desc_count}ê°œ ìƒì„±)")

                except Exception as e:
                    self.logger.warning(f"âŒ í…Œì´ë¸” {tbl_idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

                tbl_idx += 1

            # ì´ë¯¸ì§€ ì²˜ë¦¬
            elif isinstance(item, PictureItem):
                try:
                    # JUNK ì´ë¯¸ì§€ í•„í„°ë§
                    if img_idx in junk_image_indices:
                        self.logger.debug(f"â­ï¸  ì´ë¯¸ì§€ {img_idx} JUNKìœ¼ë¡œ ìŠ¤í‚µ")
                        if self.advanced_mode:
                            junk_skipped += 1
                        img_idx += 1
                        continue

                    # ì´ë¯¸ì§€ ì €ì¥
                    img = item.get_image(doc)
                    image_path = images_dir / f"image-{img_idx}.png"
                    img.save(image_path, "PNG")
                    self.logger.debug(f"ì´ë¯¸ì§€ ì €ì¥: {image_path}")

                    # ê³ ê¸‰ ëª¨ë“œ: VLM description ìƒì„±
                    if self.enable_image_description and "pictures" in doc_dict:
                        if img_idx < len(doc_dict["pictures"]):
                            picture_node = doc_dict["pictures"][img_idx]

                            self.logger.info(f"ğŸ”„ ì´ë¯¸ì§€ description ìƒì„± ì¤‘ [{img_idx + 1 - junk_skipped}/{total_images - len(junk_image_indices)}]...")

                            # Progress callback í˜¸ì¶œ
                            if self.progress_callback:
                                self.progress_callback({
                                    'status': f'Generating image description [{img_idx + 1 - junk_skipped}/{total_images - len(junk_image_indices)}]',
                                    'progress': 40 + int((img_idx / total_images) * 20),
                                    'current_image': img_idx + 1 - junk_skipped,
                                    'total_images': total_images - len(junk_image_indices),
                                })

                            desc = self._generate_vlm_description(img)
                            if desc:
                                if desc.strip().upper() == "JUNK":
                                    picture_node["classification"] = "JUNK"
                                    self.logger.info(f"ğŸ—‘ï¸  ì´ë¯¸ì§€ [{img_idx + 1 - junk_skipped}] VLMì´ JUNKë¡œ ë¶„ë¥˜")
                                else:
                                    if "annotations" not in picture_node:
                                        picture_node["annotations"] = []
                                    picture_node["annotations"].append({
                                        "kind": "description",
                                        "label": "vlm_image_description",
                                        "text": desc
                                    })
                                    image_desc_count += 1
                                    self.logger.info(f"âœ… ì´ë¯¸ì§€ [{img_idx + 1 - junk_skipped}/{total_images - len(junk_image_indices)}] description ì™„ë£Œ (ì´ {image_desc_count}ê°œ ìƒì„±)")

                except Exception as e:
                    self.logger.warning(f"âŒ ì´ë¯¸ì§€ {img_idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

                img_idx += 1

        # ê³ ê¸‰ ëª¨ë“œ ìµœì¢… ê²°ê³¼
        if self.advanced_mode:
            self.logger.info(f"ğŸ‰ ê³ ê¸‰ ëª¨ë“œ ì²˜ë¦¬ ì™„ë£Œ:")
            if self.enable_table_description:
                self.logger.info(f"   - í…Œì´ë¸” description: {table_desc_count}/{total_tables}ê°œ ìƒì„±")
            if self.enable_image_description:
                self.logger.info(f"   - ì´ë¯¸ì§€ description: {image_desc_count}/{total_images}ê°œ ìƒì„±")

        return doc_dict

    # ===== Dual Content ì²­í‚¹ ë©”ì„œë“œ =====

    def _generate_chunk_id(self, source_file: str, chunk_index: int, content: str) -> str:
        """Deterministic UUID ìƒì„±"""
        content_prefix = content[:100] if content else ""
        unique_str = f"{source_file}|{chunk_index}|{content_prefix}"
        chunk_uuid = uuid5(NAMESPACE_DNS, unique_str)
        return str(chunk_uuid)

    def _generate_section_id(self, source_file: str, section_header: str) -> str:
        """Deterministic Section ID ìƒì„±"""
        unique_str = f"{source_file}|section|{section_header}"
        section_uuid = uuid5(NAMESPACE_DNS, unique_str)
        return str(section_uuid)

    def _estimate_tokens(self, text: str) -> int:
        """í…ìŠ¤íŠ¸ì˜ í† í° ìˆ˜ ì¶”ì •"""
        words = text.split()
        chars = len(text)
        return int(max(len(words) * 1.3, chars * 0.8))

    def _split_into_sentences(self, text: str) -> list[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• """
        try:
            sentences = sent_tokenize(text)
            return [s.strip() for s in sentences if s.strip()]
        except Exception as e:
            self.logger.warning(f"NLTK sent_tokenize ì‹¤íŒ¨, ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ëŒ€ì²´: {e}")
            sentences = re.split(r'(?<=[.!?\n])\s+', text)
            return [s.strip() for s in sentences if s.strip()]

    def _get_item_by_ref(self, ref: str, data: dict) -> dict | None:
        """$ref ë¬¸ìì—´ë¡œ ì‹¤ì œ í•­ëª© ê°€ì ¸ì˜¤ê¸°"""
        if not ref or not ref.startswith('#/'):
            return None

        parts = ref.strip('#/').split('/')
        if len(parts) != 2:
            return None

        collection, idx = parts
        try:
            return data.get(collection, [])[int(idx)]
        except (IndexError, ValueError):
            return None

    def _build_asset_captions(self, data: dict) -> dict[str, list[dict[str, Any]]]:
        """ì—ì…‹(í…Œì´ë¸”/ê·¸ë¦¼)ì˜ ìº¡ì…˜ì„ ìˆ˜ì§‘"""
        caps: dict[str, list[dict[str, Any]]] = {}
        for n in data.get("texts", []):
            if (n.get("label") or "").strip().lower() != "caption":
                continue
            parent = n.get("parent") or {}
            cref = parent.get("cref") or parent.get("$ref")
            if not isinstance(cref, str) or not self.ref_re.match(cref):
                continue
            txt = (n.get("text") or n.get("orig") or "").strip()
            if not txt:
                continue
            pg = (n.get("prov") or [{}])[0].get("page_no")
            caps.setdefault(cref, []).append({"text": txt, "page_no": pg})
        return caps

    def _get_page_no(self, node: dict) -> int:
        """ë…¸ë“œì—ì„œ í˜ì´ì§€ ë²ˆí˜¸ ì¶”ì¶œ"""
        prov = node.get("prov") or []
        if prov and isinstance(prov[0], dict):
            p = prov[0].get("page_no")
            if isinstance(p, int):
                return p
        return 1

    def _create_asset_summary(self, tables: list, pictures: list, formulas: list) -> dict[str, Any]:
        """ì—ì…‹ ìš”ì•½ ì •ë³´ ìƒì„±"""
        table_count = len(tables)
        picture_count = len(pictures)
        formula_count = len(formulas)
        total_count = table_count + picture_count + formula_count

        return {
            "total_count": total_count,
            "has_tables": table_count > 0,
            "has_pictures": picture_count > 0,
            "has_formulas": formula_count > 0,
            "table_count": table_count,
            "picture_count": picture_count,
            "formula_count": formula_count,
        }

    def _build_asset_metadata(self, data: dict, captions_by_ref: dict) -> tuple[dict[str, dict[str, Any]], dict[str, int]]:
        """ëª¨ë“  ì—ì…‹ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ + ìˆœì„œ ì •ë³´"""
        all_assets: dict[str, dict[str, Any]] = {}
        asset_order: dict[str, int] = {}
        order_counter = 0

        # Tombstone ë° JUNK ì´ë¯¸ì§€ ì¸ë±ìŠ¤ ìˆ˜ì§‘
        deleted_pidx: set[int] = {
            i for i, pic in enumerate(data.get("pictures", []))
            if isinstance(pic, dict) and pic.get("deleted") is True
        }

        junk_pidx: set[int] = set()
        if self.filter_junk_images:
            junk_pidx = {
                i for i, pic in enumerate(data.get("pictures", []))
                if isinstance(pic, dict) and pic.get("classification") == "JUNK"
            }

        # body children ìˆœíšŒí•˜ì—¬ ìˆœì„œ ì •ë³´ ìˆ˜ì§‘
        body = data.get('body', {})
        children = body.get('children', [])

        for child_ref_obj in children:
            ref = child_ref_obj.get('$ref', '')
            if not ref:
                continue

            # í…Œì´ë¸” ë˜ëŠ” ì´ë¯¸ì§€
            if ref.startswith('#/tables/') or ref.startswith('#/pictures/'):
                # ì´ë¯¸ì§€ í•„í„°ë§ ì²´í¬
                if ref.startswith('#/pictures/'):
                    idx = int(ref.split('/')[-1])
                    if idx in deleted_pidx or idx in junk_pidx:
                        continue

                asset_order[ref] = order_counter
                order_counter += 1

            # Formula ì²´í¬
            elif ref.startswith('#/texts/'):
                item = self._get_item_by_ref(ref, data)
                if item and item.get('label') == 'formula':
                    asset_order[ref] = order_counter
                    order_counter += 1

        # í…Œì´ë¸” ë©”íƒ€ë°ì´í„°
        for idx, table_data in enumerate(data.get('tables', [])):
            ref = f"#/tables/{idx}"
            if ref not in asset_order:
                continue

            prov = table_data.get("prov", [])
            page_no = prov[0].get("page_no", 1) if prov and isinstance(prov[0], dict) else 1

            asset_entry = {
                "uid": table_data.get("self_ref") or table_data.get("uid") or table_data.get("id"),
                "ref_norm": ref,
                "page_no": page_no,
                "captions": captions_by_ref.get(ref, []),
                "_type": "tables",
                "_order": asset_order[ref],
            }

            # í…Œì´ë¸” Markdown ë³€í™˜
            tbl_data = table_data.get("data")
            if tbl_data:
                md_table = _docling_table_to_markdown(tbl_data)
                if md_table:
                    asset_entry["markdown_table"] = md_table

            # í…Œì´ë¸” description
            if self.include_descriptions:
                annotations = table_data.get("annotations", [])
                for annot in annotations:
                    if isinstance(annot, dict) and annot.get("label") == "llm_table_summary":
                        description = annot.get("text", "").strip()
                        if description:
                            asset_entry["description"] = description
                            break

            all_assets[ref] = asset_entry

        # ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„°
        for idx, picture_data in enumerate(data.get('pictures', [])):
            ref = f"#/pictures/{idx}"
            if ref not in asset_order:
                continue

            # Tombstone ë° JUNK ì œì™¸
            if idx in deleted_pidx or idx in junk_pidx:
                continue
            if picture_data.get("deleted") is True:
                continue

            prov = picture_data.get("prov", [])
            page_no = prov[0].get("page_no", 1) if prov and isinstance(prov[0], dict) else 1

            asset_entry = {
                "uid": picture_data.get("self_ref") or picture_data.get("uid") or picture_data.get("id"),
                "ref_norm": ref,
                "page_no": page_no,
                "captions": captions_by_ref.get(ref, []),
                "classification": picture_data.get("classification"),
                "_type": "pictures",
                "_order": asset_order[ref],
            }

            # ì´ë¯¸ì§€ description
            if self.include_descriptions:
                annotations = picture_data.get("annotations", [])
                for annot in annotations:
                    if isinstance(annot, dict) and annot.get("label") == "vlm_image_description":
                        description = annot.get("text", "").strip()
                        if description:
                            asset_entry["description"] = description
                            break

            all_assets[ref] = asset_entry

        # Formula ë©”íƒ€ë°ì´í„°
        for idx, text_data in enumerate(data.get('texts', [])):
            if text_data.get('label') != 'formula':
                continue

            ref = f"#/texts/{idx}"
            if ref not in asset_order:
                continue

            formula_text = text_data.get('orig') or text_data.get('text', '')
            if not formula_text:
                continue

            prov = text_data.get("prov", [])
            page_no = prov[0].get("page_no", 1) if prov and isinstance(prov[0], dict) else 1

            asset_entry = {
                "uid": text_data.get("self_ref") or text_data.get("uid") or text_data.get("id"),
                "ref_norm": ref,
                "page_no": page_no,
                "formula": formula_text.strip(),
                "_type": "formulas",
                "_order": asset_order[ref],
            }

            all_assets[ref] = asset_entry

        return all_assets, asset_order

    def _chunk_text_only(self, data: dict, all_assets: dict) -> list[dict]:
        """
        Step 1: í…ìŠ¤íŠ¸ì™€ ì—ì…‹ì„ inlineìœ¼ë¡œ ì²­í‚¹

        Returns:
            í…ìŠ¤íŠ¸ + inline ì—ì…‹ í¬í•¨ëœ ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        chunks = []
        current_chunk = {
            "section_header": "",
            "content": "",  # ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ
            "content_with_asset": "",  # í…ìŠ¤íŠ¸ + inline ì—ì…‹
            "content_token_count": 0,
            "pages": set(),
            "asset_refs": set(),
        }

        section_chunk_indices: dict[str, int] = {}

        # pending_assets: ë‹¤ìŒ í…ìŠ¤íŠ¸ ì•ì— ì‚½ì…ë  ì—ì…‹ë“¤
        # (ref, page_no, content_text, llm_text): contentìš© í…ìŠ¤íŠ¸ì™€ LLMìš© í…ìŠ¤íŠ¸ ë¶„ë¦¬
        pending_assets: list[tuple[str, int, str, str]] = []

        # body children ìˆœíšŒ (groupsë¥¼ ì¬ê·€ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ deque ì‚¬ìš©)
        from collections import deque

        body = data.get('body', {})
        children = body.get('children', [])
        children_queue = deque(children)

        while children_queue:
            child_ref = children_queue.popleft()
            ref = child_ref.get('$ref', '')
            item = self._get_item_by_ref(ref, data)

            if not item:
                continue

            label = item.get('label', '')
            page_no = self._get_page_no(item)

            # ì œì™¸í•  í•­ëª©
            if label in self.exclude_labels:
                continue

            # í…Œì´ë¸” ì²˜ë¦¬
            if ref.startswith('#/tables/'):
                if ref in all_assets:
                    asset = all_assets[ref]
                    table_idx = ref.split('/')[-1]
                    captions = asset.get("captions", [])
                    description = asset.get("description", "")
                    markdown_table = asset.get("markdown_table", "")
                    
                    # contentìš©: Caption ìš°ì„ , ì—†ìœ¼ë©´ Description
                    content_text = ""
                    if captions:
                        content_text = f"[TABLE:table-{table_idx}] {captions[0]['text']}"
                    elif self.include_descriptions and description:
                        content_text = f"[TABLE:table-{table_idx}] {description}"
                    
                    # content_for_llmìš©: Caption + Markdown Table + Description ëª¨ë‘ í¬í•¨
                    llm_text_parts = []
                    if captions:
                        llm_text_parts.append(f"[TABLE:table-{table_idx}] {captions[0]['text']}")
                    if markdown_table:
                        llm_text_parts.append(f"```markdown\n{markdown_table}\n```")
                    if self.include_descriptions and description:
                        llm_text_parts.append(f"[TABLE Description: {description}]")
                    llm_text = "\n\n".join(llm_text_parts) if llm_text_parts else ""
                    
                    pending_assets.append((ref, page_no, content_text, llm_text))
                continue

            # ì´ë¯¸ì§€ ì²˜ë¦¬
            if ref.startswith('#/pictures/'):
                if ref in all_assets:
                    asset = all_assets[ref]
                    image_idx = ref.split('/')[-1]
                    captions = asset.get("captions", [])
                    description = asset.get("description", "")
                    
                    # contentìš©: Caption ìš°ì„ , ì—†ìœ¼ë©´ Description
                    content_text = ""
                    if captions:
                        content_text = f"[IMAGE:image-{image_idx}] {captions[0]['text']}"
                    elif self.include_descriptions and description:
                        content_text = f"[IMAGE:image-{image_idx}] {description}"
                    
                    # content_for_llmìš©: Caption + Description ëª¨ë‘ í¬í•¨
                    llm_text_parts = []
                    if captions:
                        llm_text_parts.append(f"[IMAGE:image-{image_idx}] {captions[0]['text']}")
                    if self.include_descriptions and description:
                        llm_text_parts.append(f"[IMAGE Description: {description}]")
                    llm_text = "\n".join(llm_text_parts) if llm_text_parts else ""
                    
                    pending_assets.append((ref, page_no, content_text, llm_text))
                continue

            # Formula ì²˜ë¦¬
            if label == 'formula':
                if ref in all_assets:
                    asset = all_assets[ref]
                    formula_text = asset.get("formula", "")
                    if formula_text:
                        formula_idx = ref.split('/')[-1]
                        asset_text = f"[FORMULA:formula-{formula_idx}] {formula_text}"
                        # FormulaëŠ” contentì™€ content_for_llm ë™ì¼
                        pending_assets.append((ref, page_no, asset_text, asset_text))
                    else:
                        pending_assets.append((ref, page_no, "", ""))
                continue

            # Groups ì²˜ë¦¬ (list ë“±)
            # groupsì˜ childrenì„ ì¬ê·€ì ìœ¼ë¡œ ì²˜ë¦¬ (ìˆœì„œ ìœ ì§€í•˜ë©° í ì•ì— ì‚½ì…)
            if ref.startswith('#/groups/'):
                group_children = item.get('children', [])
                # ìˆœì„œë¥¼ ìœ ì§€í•˜ë©° í ì•ì— ì‚½ì… (í˜„ì¬ ìœ„ì¹˜ ë°”ë¡œ ë‹¤ìŒì— ì²˜ë¦¬)
                children_queue.extendleft(reversed(group_children))
                continue

            # í…ìŠ¤íŠ¸ ë…¸ë“œ ì²˜ë¦¬
            # text: ì •ê·œí™”ëœ í…ìŠ¤íŠ¸ (Doclingì´ ì²˜ë¦¬, ì¤„ë°”ê¿ˆ ì œê±°ë¨)
            # orig: ì›ë³¸ í…ìŠ¤íŠ¸ (ì¤„ë°”ê¿ˆ í¬í•¨)
            text = item.get('text', '').strip()  # contentìš©: ì •ëˆëœ í…ìŠ¤íŠ¸
            text_raw_orig = item.get('orig', item.get('text', ''))  # ì›ë³¸ í…ìŠ¤íŠ¸ (fallback to text)
            text_for_llm = text_raw_orig.lstrip() if text_raw_orig else text  # content_for_llmìš©: ì›ë³¸ ì¤„ë°”ê¿ˆ ë³´ì¡´

            if not text:
                continue

            # pending_assetsë¥¼ í˜„ì¬ í…ìŠ¤íŠ¸ ì•ì— ì¶”ê°€
            for asset_ref, asset_page, content_text, llm_text in pending_assets:
                current_chunk["asset_refs"].add(asset_ref)
                current_chunk["pages"].add(asset_page)

                # contentì—ëŠ” ê°„ê²°í•œ í…ìŠ¤íŠ¸ë§Œ (caption ìš°ì„ )
                if content_text:
                    current_chunk['content'] += content_text + "\n\n"
                
                # content_with_asset (LLMìš©)ì—ëŠ” ìƒì„¸ í…ìŠ¤íŠ¸ (caption + description)
                if llm_text:
                    current_chunk['content_with_asset'] += llm_text + "\n\n"

            # pending_assets ì´ˆê¸°í™”
            pending_assets = []

            estimated_tokens = self._estimate_tokens(text)

            # section_header: ìƒˆë¡œìš´ ì„¹ì…˜ ì‹œì‘
            if label == 'section_header':
                # ì´ì „ ì²­í¬ ì €ì¥
                if current_chunk['content'].strip():
                    self._save_text_chunk(chunks, current_chunk, section_chunk_indices)
                    current_chunk = {
                        "section_header": text,
                        "content": "",
                        "content_with_asset": "",
                        "content_token_count": 0,
                        "pages": set(),
                        "asset_refs": set(),
                    }
                else:
                    # ë‚´ìš©ì´ ì—†ìœ¼ë©´ í—¤ë” ì—°ê²°
                    if current_chunk['section_header']:
                        current_chunk['section_header'] += " > " + text
                    else:
                        current_chunk['section_header'] = text

            # ì¼ë°˜ í…ìŠ¤íŠ¸ ì¶”ê°€
            else:
                # ë‹¨ì¼ í…ìŠ¤íŠ¸ ë…¸ë“œê°€ max_tokens ì´ˆê³¼: ë¬¸ì¥ ë‹¨ìœ„ ë¶„í• 
                if estimated_tokens > self.max_tokens:
                    if current_chunk['content'].strip():
                        self._save_text_chunk(chunks, current_chunk, section_chunk_indices)
                        current_chunk = {
                            "section_header": current_chunk['section_header'],
                            "content": "",
                            "content_with_asset": "",
                            "content_token_count": 0,
                            "pages": set(),
                            "asset_refs": set(),
                        }

                    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
                    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
                    sentences = self._split_into_sentences(text)
                    for sentence in sentences:
                        sentence_tokens = self._estimate_tokens(sentence)

                        # ë¬¸ì¥ í•˜ë‚˜ê°€ max_tokens ì´ˆê³¼í•˜ë©´ ê·¸ëŒ€ë¡œ ì €ì¥
                        if sentence_tokens > self.max_tokens:
                            if current_chunk['content'].strip():
                                self._save_text_chunk(chunks, current_chunk, section_chunk_indices)
                                current_chunk = {
                                    "section_header": current_chunk['section_header'],
                                    "content": "",
                                    "content_with_asset": "",
                                    "content_token_count": 0,
                                    "pages": set(),
                                    "asset_refs": set(),
                                }

                            temp_chunk = {
                                "section_header": current_chunk['section_header'],
                                "content": sentence,  # content: ì •ëˆëœ í˜•ì‹
                                "content_with_asset": sentence,  # ë¬¸ì¥ ë¶„í• ì€ ì´ë¯¸ ì •ëˆëœ í…ìŠ¤íŠ¸ ì‚¬ìš©
                                "content_token_count": sentence_tokens,
                                "pages": {page_no},
                                "asset_refs": set(),
                            }
                            self._save_text_chunk(chunks, temp_chunk, section_chunk_indices)
                            continue

                        # í˜„ì¬ ì²­í¬ì— ì¶”ê°€í•˜ë©´ max_tokens ì´ˆê³¼
                        if current_chunk['content'].strip() and current_chunk['content_token_count'] + sentence_tokens > self.max_tokens:
                            self._save_text_chunk(chunks, current_chunk, section_chunk_indices)
                            current_chunk = {
                                "section_header": current_chunk['section_header'],
                                "content": "",
                                "content_with_asset": "",
                                "content_token_count": 0,
                                "pages": set(),
                                "asset_refs": set(),
                            }

                        # content: ì •ëˆëœ í˜•ì‹ (ê³µë°±ìœ¼ë¡œ ì—°ê²°)
                        current_chunk['content'] += sentence + " "
                        # content_with_asset: ì›ë³¸ í˜•ì‹ ë³´ì¡´
                        current_chunk['content_with_asset'] += sentence + " "
                        current_chunk['content_token_count'] += sentence_tokens
                        current_chunk["pages"].add(page_no)

                # í˜„ì¬ ì²­í¬ì— ì¶”ê°€í•˜ë©´ max_tokens ì´ˆê³¼
                elif current_chunk['content'].strip() and current_chunk['content_token_count'] + estimated_tokens > self.max_tokens:
                    self._save_text_chunk(chunks, current_chunk, section_chunk_indices)
                    current_chunk = {
                        "section_header": current_chunk['section_header'],
                        "content": text + " ",  # content: ì •ëˆëœ í˜•ì‹
                        "content_with_asset": text_for_llm if text_for_llm.endswith('\n') else text_for_llm + " ",  # LLMìš©: ì›ë³¸ ì¤„ë°”ê¿ˆ ë³´ì¡´
                        "content_token_count": estimated_tokens,
                        "pages": {page_no},
                        "asset_refs": set(),
                    }

                # í˜„ì¬ ì²­í¬ì— í…ìŠ¤íŠ¸ ì¶”ê°€
                else:
                    # content: ì •ëˆëœ í˜•ì‹ (ê³µë°±ìœ¼ë¡œ ì—°ê²°)
                    current_chunk['content'] += text + " "
                    # content_with_asset: ì›ë³¸ í˜•ì‹ ë³´ì¡´ (ì¤„ë°”ê¿ˆì´ ìˆìœ¼ë©´ ìœ ì§€, ì—†ìœ¼ë©´ ê³µë°±)
                    current_chunk['content_with_asset'] += text_for_llm if text_for_llm.endswith('\n') else text_for_llm + " "
                    current_chunk['content_token_count'] += estimated_tokens
                    current_chunk["pages"].add(page_no)

        # ë‚¨ì€ pending_assets ì²˜ë¦¬
        for asset_ref, asset_page, content_text, llm_text in pending_assets:
            current_chunk["asset_refs"].add(asset_ref)
            current_chunk["pages"].add(asset_page)

            if content_text:
                current_chunk['content'] += content_text + "\n\n"
            
            if llm_text:
                current_chunk['content_with_asset'] += llm_text + "\n\n"

        # ë§ˆì§€ë§‰ ì²­í¬ ì €ì¥
        if current_chunk['content'].strip():
            self._save_text_chunk(chunks, current_chunk, section_chunk_indices)

        return chunks

    def _save_text_chunk(self, chunks: list[dict], current_chunk: dict, section_chunk_indices: dict[str, int]):
        """í…ìŠ¤íŠ¸ ì²­í¬ ì €ì¥ (Step 1)"""
        if not current_chunk['content'].strip():
            return

        # ìµœì†Œ í† í° ìˆ˜ ì²´í¬
        token_count = self._estimate_tokens(current_chunk['content'])
        if (chunks and
            token_count < self.min_chunk_tokens and
            chunks[-1]['section_header'] == current_chunk['section_header']):

            # ì´ì „ ì²­í¬ì— ë³‘í•©
            prev_chunk = chunks[-1]
            prev_chunk['content'] = prev_chunk['content'] + " " + current_chunk['content'].strip()
            prev_chunk['content_with_asset'] = prev_chunk['content_with_asset'] + " " + current_chunk['content_with_asset'].strip()
            prev_chunk['pages'] = sorted(list(set(prev_chunk['pages']) | current_chunk['pages']))
            prev_chunk['asset_refs'] = prev_chunk['asset_refs'] | current_chunk['asset_refs']
            return

        # ì„¹ì…˜ë³„ ì²­í¬ ì¸ë±ìŠ¤
        section_header = current_chunk['section_header']
        chunk_index = section_chunk_indices.get(section_header, 0)
        section_chunk_indices[section_header] = chunk_index + 1

        # ì²­í¬ ì €ì¥
        chunks.append({
            "chunk_index": chunk_index,
            "section_header": section_header,
            "content": current_chunk['content'].strip(),
            "content_with_asset": current_chunk['content_with_asset'].strip(),
            "pages": sorted(list(current_chunk['pages'])) if current_chunk['pages'] else [1],
            "asset_refs": current_chunk['asset_refs'],
        })

    def _create_dual_content(self, chunks: list[dict], all_assets: dict[str, dict[str, Any]]):
        """Step 2: Dual Content ì™„ì„±"""
        for chunk in chunks:
            asset_refs = chunk.pop('asset_refs', set())
            content_with_asset = chunk.pop('content_with_asset', chunk['content'])
            clean_content = chunk['content']

            # content_for_llmìœ¼ë¡œ rename
            chunk['content_for_llm'] = content_with_asset

            if not asset_refs:
                chunk['assets'] = []
                chunk['asset_summary'] = self._create_asset_summary([], [], [])
                continue

            # ì—ì…‹ì„ ìˆœì„œëŒ€ë¡œ ì •ë ¬
            sorted_refs = sorted(asset_refs, key=lambda ref: all_assets.get(ref, {}).get('_order', 999))

            # assets ìƒì„± + appendix ë§ˆì»¤ ìƒì„±
            assets = []
            appendix_markers = []

            for ref in sorted_refs:
                if ref not in all_assets:
                    continue

                asset = all_assets[ref].copy()
                asset_type = asset.pop("_type", "pictures")
                asset.pop("_order", 0)

                # assetsì— ì¶”ê°€
                asset["type"] = asset_type
                assets.append(asset)

                # embed_with_assets=Trueì¼ ë•Œ appendix ë§ˆì»¤ ìƒì„±
                if self.embed_with_assets:
                    if asset_type == "tables":
                        table_idx = ref.split('/')[-1]
                        description = asset.get("description", "")
                        captions = asset.get("captions", [])

                        if self.include_descriptions and description:
                            appendix_markers.append(f"[TABLE:table-{table_idx}] {description}")
                        elif captions:
                            appendix_markers.append(f"[TABLE Caption: {captions[0]['text']}]")

                    elif asset_type == "pictures":
                        image_idx = ref.split('/')[-1]
                        description = asset.get("description", "")
                        captions = asset.get("captions", [])

                        if self.include_descriptions and description:
                            appendix_markers.append(f"[IMAGE:image-{image_idx}] {description}")
                        elif captions:
                            appendix_markers.append(f"[IMAGE Caption: {captions[0]['text']}]")

                    elif asset_type == "formulas":
                        formula_idx = ref.split('/')[-1]
                        formula_text = asset.get("formula", "")
                        if formula_text:
                            appendix_markers.append(f"[FORMULA:formula-{formula_idx}] {formula_text}")

            # content: embed_with_assets=Trueì¼ ë•Œ appendix ì¶”ê°€
            if self.embed_with_assets and appendix_markers:
                chunk['content'] = clean_content + "\n\n" + "\n".join(appendix_markers)
            else:
                chunk['content'] = clean_content

            # assets ì €ì¥
            chunk['assets'] = assets

            # asset_summary
            tables = [a for a in assets if a.get('type') == 'tables']
            pictures = [a for a in assets if a.get('type') == 'pictures']
            formulas = [a for a in assets if a.get('type') == 'formulas']
            chunk['asset_summary'] = self._create_asset_summary(tables, pictures, formulas)

    def chunk_docling_dict(self, doc_dict: dict, source_filename: str) -> Tuple[list[dict], str]:
        """
        Docling JSON ë”•ì…”ë„ˆë¦¬ë¥¼ ì²­í‚¹

        Args:
            doc_dict: Docling JSON ë”•ì…”ë„ˆë¦¬
            source_filename: ì›ë³¸ íŒŒì¼ëª…

        Returns:
            (ì²­í¬ ë¦¬ìŠ¤íŠ¸, ì›ë³¸ íŒŒì¼ëª…) íŠœí”Œ
        """
        self.logger.info(f"Dual Content ì²­í‚¹ ì‹œì‘: {source_filename}")

        # Description ê°€ìš©ì„± ì²´í¬
        if self.include_descriptions:
            pictures = doc_dict.get("pictures", [])
            tables = doc_dict.get("tables", [])

            image_desc_count = sum(
                1 for pic in pictures
                if isinstance(pic, dict) and any(
                    isinstance(annot, dict) and annot.get("label") == "vlm_image_description"
                    for annot in pic.get("annotations", [])
                )
            )
            table_desc_count = sum(
                1 for tbl in tables
                if isinstance(tbl, dict) and any(
                    isinstance(annot, dict) and annot.get("label") == "llm_table_summary"
                    for annot in tbl.get("annotations", [])
                )
            )

            if (image_desc_count == 0 and len(pictures) > 0) or (table_desc_count == 0 and len(tables) > 0):
                self.logger.warning(
                    f"âš ï¸  Descriptionì´ ìš”ì²­ë˜ì—ˆìœ¼ë‚˜ JSONì— ì—†ìŠµë‹ˆë‹¤. "
                    f"advanced_mode=Trueë¡œ ì„¤ì •í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. "
                    f"(ì´ë¯¸ì§€: {image_desc_count}/{len(pictures)}, í…Œì´ë¸”: {table_desc_count}/{len(tables)})"
                )

        # ìº¡ì…˜ ìˆ˜ì§‘
        captions_by_ref = self._build_asset_captions(doc_dict)

        # ì—ì…‹ ë©”íƒ€ë°ì´í„° êµ¬ì¶•
        self.logger.info("Step 0: ì—ì…‹ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        all_assets, asset_order = self._build_asset_metadata(doc_dict, captions_by_ref)
        self.logger.info(f"  ì—ì…‹ ì´ {len(all_assets)}ê°œ ë°œê²¬")

        # Step 1: í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ ì²­í‚¹
        self.logger.info("Step 1: í…ìŠ¤íŠ¸ ì²­í‚¹ ì¤‘...")
        chunks = self._chunk_text_only(doc_dict, all_assets)
        self.logger.info(f"  {len(chunks)}ê°œ í…ìŠ¤íŠ¸ ì²­í¬ ìƒì„±")

        # Step 2: Dual Content ìƒì„±
        self.logger.info("Step 2: Dual Content ìƒì„± ì¤‘...")
        self._create_dual_content(chunks, all_assets)
        self.logger.info(f"  Dual Content ìƒì„± ì™„ë£Œ")

        # Step 3: section_headerë¥¼ contentì™€ content_for_llmì— ì¶”ê°€ (ê²€ìƒ‰ ìµœì í™”)
        self.logger.info("Step 3: section_headerë¥¼ contentì™€ content_for_llmì— ì¶”ê°€ ì¤‘...")
        for chunk in chunks:
            section_header = chunk.get('section_header', '').strip()
            if section_header:
                # contentì— section_header ì¶”ê°€ (í† í° ê³„ì‚°ì€ ì´ë¯¸ ì™„ë£Œëœ ìƒíƒœ)
                original_content = chunk.get('content', '')
                chunk['content'] = f"Section: {section_header}\n\n{original_content}"

                # content_for_llmì—ë„ section_header ì¶”ê°€
                original_content_for_llm = chunk.get('content_for_llm', '')
                chunk['content_for_llm'] = f"Section: {section_header}\n\n{original_content_for_llm}"
        self.logger.info(f"  section_header ì¶”ê°€ ì™„ë£Œ")

        self.logger.info(f"âœ… Dual Content ì²­í‚¹ ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
        return chunks, source_filename

    # ===== í†µí•© ì²˜ë¦¬ ë©”ì„œë“œ =====

    def process_pdf_to_chunks(
        self,
        pdf_path: Path,
        output_dir: Path,
        original_filename: Optional[str] = None,
    ) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        """
        PDFë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ì—¬ ì²­í¬ ìƒì„± (Docling â†’ Chunks)

        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (assets ì €ì¥ìš©)
            original_filename: ì›ë³¸ íŒŒì¼ëª… (ì—†ìœ¼ë©´ pdf_path.name ì‚¬ìš©)

        Returns:
            (chunks_list, metadata)
            metadata: {
                "table_count": int,
                "picture_count": int,
                "chunk_count": int,
                "source_file": str
            }
        """
        # ì›ë³¸ íŒŒì¼ëª… ê²°ì •
        if original_filename is None:
            original_filename = pdf_path.name

        # assets ë””ë ‰í† ë¦¬ëª…: ì›ë³¸ íŒŒì¼ëª… ì‚¬ìš© (í™•ì¥ì ì œì™¸)
        original_stem = Path(original_filename).stem
        assets_dir = output_dir / f"{original_stem}_assets"

        # Step 1: Docling ì²˜ë¦¬
        doc_dict = self.convert_to_dict(pdf_path, assets_dir)

        # ì›ë³¸ íŒŒì¼ëª… ê²°ì • (ì „ë‹¬ë°›ì€ original_filename ìš°ì„  ì‚¬ìš©)
        if original_filename:
            source_filename = original_filename
        else:
            origin = doc_dict.get('origin', {})
            source_filename = origin.get('filename', pdf_path.name)

        # Step 2: ì²­í‚¹
        chunks, source_filename = self.chunk_docling_dict(doc_dict, source_filename)

        # Step 3: ë©”íƒ€ë°ì´í„° ì¶”ê°€
        for chunk in chunks:
            chunk['source_file'] = source_filename

            # Deterministic Chunk ID ìƒì„±
            chunk_id = self._generate_chunk_id(
                source_file=source_filename,
                chunk_index=chunk['chunk_index'],
                content=chunk['content']
            )
            chunk['chunk_id'] = chunk_id

            # Deterministic Section ID ìƒì„±
            section_id = self._generate_section_id(
                source_file=source_filename,
                section_header=chunk['section_header']
            )
            chunk['section_id'] = section_id

        # ë©”íƒ€ë°ì´í„°
        # OCR ì •ë³´ ì¶”ì¶œ
        if self.last_ocr_result:
            ocr_used = self.last_ocr_result.needs_ocr
            ocr_reason = self.last_ocr_result.reason
            total_pages = self.last_ocr_result.total_pages
            text_layer_ratio = self.last_ocr_result.text_layer_ratio
        else:
            # OCR ê°ì§€ë¥¼ í•˜ì§€ ì•Šì€ ê²½ìš° (force_ocr, force_no_ocr ì‚¬ìš© ì‹œ)
            if self.force_ocr:
                ocr_used = True
                ocr_reason = "OCR ê°•ì œ í™œì„±í™”"
            elif self.force_no_ocr:
                ocr_used = False
                ocr_reason = "OCR ê°•ì œ ë¹„í™œì„±í™”"
            else:
                ocr_used = False
                ocr_reason = "OCR ê°ì§€ ë¯¸ìˆ˜í–‰"
            total_pages = len(doc_dict.get("pages", []))
            text_layer_ratio = 0.0

        metadata = {
            "table_count": len(doc_dict.get("tables", [])),
            "picture_count": len([p for p in doc_dict.get("pictures", []) if not p.get("deleted")]),
            "chunk_count": len(chunks),
            "source_file": source_filename,
            "ocr_used": ocr_used,
            "ocr_reason": ocr_reason,
            "total_pages": total_pages,
            "text_layer_ratio": text_layer_ratio,
        }

        return chunks, metadata


def main():
    """CLI ì§„ì…ì """
    import argparse

    parser = argparse.ArgumentParser(
        description="Docling Complete + Chunking í†µí•© íŒŒì„œ",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument("input_pdf", type=Path, help="ë³€í™˜í•  PDF íŒŒì¼ ê²½ë¡œ")
    parser.add_argument(
        "-o", "--output-dir", type=Path, help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: PDFì™€ ê°™ì€ ìœ„ì¹˜)"
    )

    # Docling ì˜µì…˜
    parser.add_argument("--image-scale", type=float, default=2.0, help="ì´ë¯¸ì§€ í•´ìƒë„ ìŠ¤ì¼€ì¼")
    parser.add_argument("--no-table-structure", action="store_true", help="í…Œì´ë¸” êµ¬ì¡° ë¶„ì„ ë¹„í™œì„±í™”")
    parser.add_argument("--force-ocr", action="store_true", help="OCR ê°•ì œ í™œì„±í™”")
    parser.add_argument("--no-ocr", action="store_true", help="OCR ê°•ì œ ë¹„í™œì„±í™”")
    parser.add_argument(
        "--ocr-engine",
        type=str,
        default="tesseract",
        choices=["tesseract", "easyocr", "rapidocr"],
        help="OCR ì—”ì§„ ì„ íƒ",
    )
    parser.add_argument("--ocr-threshold", type=float, default=0.4, help="OCR í•„ìš” íŒë‹¨ ì„ê³„ê°’")

    # ê³ ê¸‰ ëª¨ë“œ
    parser.add_argument("--advanced", action="store_true", help="ê³ ê¸‰ ëª¨ë“œ í™œì„±í™” (VLM/LLM description ìƒì„±)")
    parser.add_argument("--no-image-desc", action="store_true", help="ì´ë¯¸ì§€ VLM description ë¹„í™œì„±í™”")
    parser.add_argument("--no-table-desc", action="store_true", help="í…Œì´ë¸” LLM description ë¹„í™œì„±í™”")
    parser.add_argument("--include-junk", action="store_true", help="JUNK ì´ë¯¸ì§€ë„ í¬í•¨")

    # ì²­í‚¹ ì˜µì…˜
    parser.add_argument("--max-tokens", type=int, default=400, help="í…ìŠ¤íŠ¸ ì²­í¬ë‹¹ ìµœëŒ€ í† í° ìˆ˜")
    parser.add_argument("--min-chunk-tokens", type=int, default=100, help="ì²­í¬ ìµœì†Œ í† í° ìˆ˜")
    parser.add_argument("--no-include-desc", action="store_false", dest="include_desc", help="description ì œì™¸")
    parser.add_argument("--embed-with-assets", action="store_true", help="content í•„ë“œì—ë„ ì—ì…‹ ì¶”ê°€")

    parser.add_argument("-v", "--verbose", action="store_true", help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥")

    args = parser.parse_args()

    # ë¡œê¹… ì„¤ì •
    log_level = logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(
        level=log_level,
        format="%(asctime)s - %(levelname)s - %(message)s",
        force=True,
    )

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    if args.output_dir:
        output_dir = args.output_dir
    else:
        output_dir = args.input_pdf.parent

    output_dir.mkdir(parents=True, exist_ok=True)

    # ì²­í‚¹ ì‹¤í–‰
    chunker = DoclingCompleteChunker(
        # Docling ì˜µì…˜
        image_scale=args.image_scale,
        enable_table_structure=not args.no_table_structure,
        force_ocr=args.force_ocr,
        force_no_ocr=args.no_ocr,
        ocr_engine=args.ocr_engine,
        ocr_threshold=args.ocr_threshold,

        # ê³ ê¸‰ ëª¨ë“œ
        advanced_mode=args.advanced,
        enable_image_description=not args.no_image_desc,
        enable_table_description=not args.no_table_desc,
        filter_junk_images=not args.include_junk,

        # ì²­í‚¹ ì˜µì…˜
        max_tokens=args.max_tokens,
        min_chunk_tokens=args.min_chunk_tokens,
        include_descriptions=args.include_desc,
        embed_with_assets=args.embed_with_assets,
    )

    try:
        chunks, metadata = chunker.process_pdf_to_chunks(args.input_pdf, output_dir)

        # ì²­í¬ JSON ì €ì¥
        chunks_json_path = output_dir / f"{args.input_pdf.stem}_chunks.json"
        with open(chunks_json_path, 'w', encoding='utf-8') as f:
            json.dump(chunks, f, ensure_ascii=False, indent=2)

        print(f"âœ… ë³€í™˜ ì™„ë£Œ: {chunks_json_path}")
        print(f"   ì²­í¬ ìˆ˜: {metadata['chunk_count']}ê°œ")
        print(f"   í…Œì´ë¸”: {metadata['table_count']}ê°œ")
        print(f"   ì´ë¯¸ì§€: {metadata['picture_count']}ê°œ")

    except Exception as e:
        print(f"âŒ ë³€í™˜ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        raise SystemExit(1)


# ===== API í˜¸í™˜ ë ˆì´ì–´ (parser.py ì¸í„°í˜ì´ìŠ¤ ëŒ€ì²´) =====

@dataclass
class IntegratedParserConfig:
    """í†µí•© íŒŒì„œ ì„¤ì • (ê³ ê¸‰ ëª¨ë“œë§Œ ë…¸ì¶œ)"""
    # ê³ ê¸‰ ëª¨ë“œ: VLM/LLM description ìƒì„±
    enable_image_description: bool = False
    enable_table_description: bool = False
    # ì„ë² ë”© ìµœì í™”: contentì— asset ì„¤ëª… appendix ì¶”ê°€
    embed_with_assets: bool = False


def process_pdf_to_chunks(
    file_content: bytes,
    filename: str,
    output_dir: Path,
    source_id: Optional[str] = None,
    config: Optional[IntegratedParserConfig] = None,
    progress_callback: Optional[callable] = None
) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
    """
    PDFë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ì—¬ ì²­í¬ ìƒì„± (Docling Complete â†’ Dual Content Chunks)

    ì´ í•¨ìˆ˜ëŠ” parser.pyì˜ process_pdf_to_chunks()ì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•˜ì§€ë§Œ,
    ë‚´ë¶€ì ìœ¼ë¡œ DoclingCompleteChunkerë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

    Args:
        file_content: PDF ë°”ì´ë„ˆë¦¬
        filename: íŒŒì¼ëª…
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (assets ì €ì¥ ìœ„ì¹˜)
        source_id: ì†ŒìŠ¤ UUID (ì—†ìœ¼ë©´ ìë™ ìƒì„±)
        config: íŒŒì„œ ì„¤ì •

    Returns:
        (chunks_list, metadata)
        chunks_list: ì²­í¬ ë¦¬ìŠ¤íŠ¸ (ê° ì²­í¬ëŠ” dict)
        metadata: {
            "table_count": int,
            "picture_count": int,
            "chunk_count": int,
            "ocr_used": bool,
            "ocr_reason": str,
            "total_pages": int,
            "text_layer_ratio": float
        }
    """
    import uuid

    if config is None:
        config = IntegratedParserConfig()

    if source_id is None:
        source_id = str(uuid.uuid4())

    # DoclingChunker ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ëª¨ë“  ì˜µì…˜ì€ ë‚´ë¶€ ê¸°ë³¸ê°’ ì‚¬ìš©)
    # ê³ ê¸‰ ëª¨ë“œë§Œ ì‚¬ìš©ìê°€ ì„ íƒ ê°€ëŠ¥
    advanced_mode_enabled = config.enable_image_description or config.enable_table_description
    logging.getLogger(__name__).info(
        f"DoclingChunker ì´ˆê¸°í™”: advanced_mode={advanced_mode_enabled}, "
        f"enable_image_description={config.enable_image_description}, "
        f"enable_table_description={config.enable_table_description}, "
        f"embed_with_assets={config.embed_with_assets}"
    )

    chunker = DoclingChunker(
        advanced_mode=advanced_mode_enabled,
        enable_image_description=config.enable_image_description,
        enable_table_description=config.enable_table_description,
        embed_with_assets=config.embed_with_assets,
        progress_callback=progress_callback,
    )

    # PDFë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ (DoclingCompleteChunkerê°€ Pathë¥¼ ë°›ê¸° ë•Œë¬¸)
    import tempfile
    with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as tmp_pdf:
        tmp_pdf.write(file_content)
        tmp_pdf_path = Path(tmp_pdf.name)

    try:
        # ì²­í¬ ìƒì„± (ì›ë³¸ íŒŒì¼ëª… ì „ë‹¬)
        chunks, metadata = chunker.process_pdf_to_chunks(
            tmp_pdf_path,
            output_dir,
            original_filename=filename
        )
        return chunks, metadata

    finally:
        # ì„ì‹œ PDF íŒŒì¼ ì‚­ì œ
        if tmp_pdf_path.exists():
            tmp_pdf_path.unlink()


if __name__ == "__main__":
    main()
